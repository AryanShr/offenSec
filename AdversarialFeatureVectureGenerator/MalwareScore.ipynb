{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1L3az8_7QCgv0iV2CcTj4sVMN6qo0LQit",
      "authorship_tag": "ABX9TyMSxRdUQOSzU7U42vWpItCO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AryanShr/offenSec/blob/main/AdversarialFeatureVectureGenerator/MalwareScore.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwQ5MDP4RDsc",
        "outputId": "edf0f65e-8831-46b1-dbef-314b7c4bb755"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Tuple\n",
        "from enum import Enum\n",
        "from typing import Union\n",
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
        "from pathlib import Path\n",
        "import pickle"
      ],
      "metadata": {
        "id": "NLZSLH_VR8Gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sklearn.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qa4cNBlcvhN-",
        "outputId": "31842cfa-19f4-4971-8fab-f23a95d0a695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.2.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TorchOrNumpy = Union[np.ndarray, torch.Tensor]"
      ],
      "metadata": {
        "id": "jROLE4xaR_RM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tYhcOAdQ1L11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BlackBoxDetector:\n",
        "    \"\"\"\n",
        "    Black box detector that intends to mimic an antivirus/anti-Malware program that detects whether\n",
        "    a specific program is either malware or benign.\n",
        "    \"\"\"\n",
        "    class Type(Enum):\n",
        "        DecisionTree = DecisionTreeClassifier()\n",
        "        # LogisticRegression = LogisticRegression(solver='lbfgs', max_iter=int(1e6))\n",
        "        LogisticRegression = LogisticRegression(solver='newton-cg')\n",
        "        MultiLayerPerceptron = MLPClassifier()\n",
        "        RandomForest = RandomForestClassifier(n_estimators=100)\n",
        "        SVM = SVC(gamma=\"auto\",probability=True)\n",
        "\n",
        "        @staticmethod\n",
        "        def names():\n",
        "            r\"\"\" Builds the list of all enum names \"\"\"\n",
        "            return [c.name for c in BlackBoxDetector.Type]\n",
        "\n",
        "        @staticmethod\n",
        "        def get_from_name(name):\n",
        "            for c in BlackBoxDetector.Type:\n",
        "                if c.name == name:\n",
        "                    return c\n",
        "            raise ValueError(\"Unknown enum \\\"%s\\\" for class \\\"%s\\\"\", name, __class__.name)\n",
        "\n",
        "    def __init__(self, learner_type: 'BlackBoxDetector.Type'):\n",
        "        self.type = learner_type\n",
        "        self._model = sklearn.clone(self.type.value)\n",
        "        self.training = True\n",
        "\n",
        "    def fit(self, X: TorchOrNumpy, y: TorchOrNumpy):\n",
        "        if isinstance(X, torch.Tensor):\n",
        "            X = X.numpy()\n",
        "        if isinstance(y, torch.Tensor):\n",
        "            y = y.numpy()\n",
        "        self._model.fit(X, y)\n",
        "        self.training = False\n",
        "\n",
        "    def predict(self, X: TorchOrNumpy) -> torch.tensor:\n",
        "        if self.training:\n",
        "            raise ValueError(\"Detector does not appear to be trained but trying to predict\")\n",
        "        if torch.cuda.is_available():\n",
        "            X = X.cpu()\n",
        "        if isinstance(X, torch.Tensor):\n",
        "            X = X.numpy()\n",
        "        print(X)\n",
        "        y = torch.from_numpy(self._model.predict(X)).float()\n",
        "        return y.cuda() if torch.cuda.is_available() else y"
      ],
      "metadata": {
        "id": "J3XvZYWTRHam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MalwareDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Encapsulates a malware dataset.  All elements in the dataset will be either malware or benign\n",
        "    \"\"\"\n",
        "    def __init__(self, x: Union[np.ndarray, torch.Tensor], y):\n",
        "        super().__init__()\n",
        "\n",
        "        if isinstance(x, np.ndarray):\n",
        "            x = torch.from_numpy(x).float()\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x[index], self.y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.x.shape[0]\n",
        "\n",
        "    @property\n",
        "    def num_features(self):\n",
        "        r\"\"\" Number of features in the dataset \"\"\"\n",
        "        return self.x.shape[1]"
      ],
      "metadata": {
        "id": "kmajhQxuJoRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class _DataGroup:\n",
        "    r\"\"\"Encapsulates either PyTorch DataLoaders or Datasets.  This class is intended only for internal use by MalGAN.\"\"\"\n",
        "    def __init__(self, train: MalwareDataset, valid: MalwareDataset, test: MalwareDataset):\n",
        "        self.train = train\n",
        "        self.valid = valid\n",
        "        self.test = test\n",
        "        self.is_loaders = False\n",
        "\n",
        "    def build_loader(self, batch_size: int = 0):\n",
        "        r\"\"\" Constructs loaders from the datasets :param batch_size: Batch size for training \"\"\"\n",
        "        self.train = DataLoader(self.train, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "        if self.valid:\n",
        "            self.valid = DataLoader(self.valid, batch_size=batch_size, pin_memory=True)\n",
        "        self.test = DataLoader(self.test, batch_size=batch_size, pin_memory=True)\n",
        "        self.is_loaders = True"
      ],
      "metadata": {
        "id": "u9JZrEPsbO_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATION_SPLIT = 0.2"
      ],
      "metadata": {
        "id": "n6yr5Yqfw-G6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yQAtC9eFxAcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_train_valid_test(dataset: Dataset, is_benign: bool):\n",
        "  \"\"\"Helper function to partition into test, train, and validation subsets\"\"\"\n",
        "  valid_len = 0 if is_benign else int(VALIDATION_SPLIT * len(dataset))\n",
        "  test_len = int(0.3 * len(dataset))\n",
        "\n",
        "  # Order must be train, validation, test\n",
        "  lengths = [len(dataset) - valid_len - test_len, valid_len, test_len]\n",
        "  return _DataGroup(*torch.utils.data.random_split(dataset, lengths))"
      ],
      "metadata": {
        "id": "fvMpzKjkv2XB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(file_path: Union[str, Path], y: int) -> MalwareDataset:\n",
        "    file_ext = Path(file_path).suffix\n",
        "    if file_ext in {\".npy\", \".npz\"}:\n",
        "        data = np.load(file_path)\n",
        "        # DEBUG\n",
        "        print(data.view())\n",
        "\n",
        "    elif file_ext in {\".pt\", \".pth\"}:\n",
        "        data = torch.load(str(file_path))\n",
        "    elif file_ext == \".pk\":\n",
        "        with open(str(file_path), \"rb\") as f_in:\n",
        "            data = pickle.load(f_in)\n",
        "    else:\n",
        "        raise ValueError(\"Unknown file extension.  Cannot determine how to import\")\n",
        "    return MalwareDataset(x=data, y=y)"
      ],
      "metadata": {
        "id": "q475Q0UTwUkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "malware_features = Path(\"/content/drive/MyDrive/Feature_Vector/malware_feature_set.pk\")\n",
        "benign_features = Path(\"/content/drive/MyDrive/Feature_Vector/benign_feature_set.pk\")"
      ],
      "metadata": {
        "id": "RumtQBNfwEVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "malware = load_dataset(str(malware_features), 1)\n",
        "benign = load_dataset(str(benign_features), 0)"
      ],
      "metadata": {
        "id": "b2ZMYLtewPtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mal_data = split_train_valid_test(malware, is_benign=False)\n",
        "ben_data = split_train_valid_test(benign, is_benign=True)\n",
        "mal_data, ben_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LhiM3m_wKIK",
        "outputId": "4a5b8545-fe98-4ca9-ff7e-5c227fecdbe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<__main__._DataGroup at 0x7dee1ffc65f0>,\n",
              " <__main__._DataGroup at 0x7dee1ffc51b0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bb = BlackBoxDetector(BlackBoxDetector.Type.RandomForest)"
      ],
      "metadata": {
        "id": "eiLfIj0Cu9P4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_x(ds: Subset) -> torch.Tensor:\n",
        "  # noinspection PyUnresolvedReferences\n",
        "  x = ds.dataset.x[ds.indices]\n",
        "  return x.cpu() if torch.cuda.is_available() else x"
      ],
      "metadata": {
        "id": "xxTYi-CrvmQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mal_x = extract_x(mal_data.train)\n",
        "ben_x = extract_x(ben_data.train)"
      ],
      "metadata": {
        "id": "P4uw-j03whs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merge_data = torch.cat((mal_x,ben_x))\n",
        "merge_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07HwYVpdwl-3",
        "outputId": "80032e43-fd4b-4e39-d80c-c3634ecbb2f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(merge_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7ANTOPDZwof",
        "outputId": "844b92e6-09d5-4347-baeb-57d56812f297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5960"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_y = torch.cat((torch.full((len(mal_data.train),), 1), torch.full((len(ben_data.train),), 0)))\n",
        "merged_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-resGR6fwqQ3",
        "outputId": "4b2703fd-fcd5-47dd-c497-1b523c92e2ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1,  ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bb.fit(merge_data,merged_y)"
      ],
      "metadata": {
        "id": "Woc6eidIwq7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "class EnsembleBlackBoxDetector:\n",
        "    def __init__(self):\n",
        "        self.models = [\n",
        "            ('DecisionTree', DecisionTreeClassifier()),\n",
        "            ('RandomForest', RandomForestClassifier()),\n",
        "            ('SVC', SVC(probability=True)),\n",
        "            ('Logistic', LogisticRegression()),\n",
        "            ('MLP', MLPClassifier())\n",
        "        ]\n",
        "        self.ensemble_model = VotingClassifier(estimators=self.models, voting='soft')\n",
        "        self.training = True\n",
        "\n",
        "    def fit(self, X: TorchOrNumpy, y: TorchOrNumpy):\n",
        "        if isinstance(X, torch.Tensor):\n",
        "            X = X.numpy()\n",
        "        if isinstance(y, torch.Tensor):\n",
        "            y = y.numpy()\n",
        "        self.ensemble_model.fit(X, y)\n",
        "        self.training = False\n",
        "\n",
        "    def predict(self, X: TorchOrNumpy) -> torch.tensor:\n",
        "        if self.training:\n",
        "            raise ValueError(\"Detector does not appear to be trained but trying to predict\")\n",
        "        if torch.cuda.is_available():\n",
        "            X = X.cpu()\n",
        "        if isinstance(X, torch.Tensor):\n",
        "            X = X.numpy()\n",
        "        print(X)\n",
        "        y = torch.from_numpy(self.ensemble_model.predict_proba(X)[:, 1]).float()\n",
        "        return y.cuda() if torch.cuda.is_available() else y\n",
        "    def save_model(self, filename):\n",
        "        with open(filename, 'wb') as file:\n",
        "            pickle.dump(self.ensemble_model, file)\n",
        "\n",
        "    @classmethod\n",
        "    def load_model(cls, filename, learner_types):\n",
        "        with open(filename, 'rb') as file:\n",
        "            ensemble_model = pickle.load(file)\n",
        "        ensemble_detector = cls(learner_types)\n",
        "        ensemble_detector.ensemble_model = ensemble_model\n",
        "        ensemble_detector.training = False\n",
        "        return ensemble_detector\n"
      ],
      "metadata": {
        "id": "PRrXnbv9xEk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EBD = EnsembleBlackBoxDetector()"
      ],
      "metadata": {
        "id": "v6YdVP4Wxh1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EBD.fit(merge_data,merged_y)"
      ],
      "metadata": {
        "id": "TyBoAKh6yVV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create some dummy data for prediction\n",
        "X_test = np.random.choice([0, 1], size=(1, 7346))\n",
        "\n",
        "# Convert numpy array to torch tensor\n",
        "X_test_torch = torch.from_numpy(X_test).float()"
      ],
      "metadata": {
        "id": "uVml3BzRycmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QiBpaYMs0Yn",
        "outputId": "ae33c29c-0e6f-4850-e421-0c3b8b448dce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 1.,  ..., 1., 1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the labels for the test data\n",
        "y_pred = EBD.predict(X_test_torch)\n",
        "\n",
        "# Print the predicted labels\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEOcJkU51kXf",
        "outputId": "ebdd8b10-23e2-4049-de6f-d1cc1eb6dde5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 1. ... 1. 1. 0.]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5808])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = X_test_torch.numpy()\n",
        "x"
      ],
      "metadata": {
        "id": "ENjsC7tW1qtA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dccf1d5a-7ad8-4250-b7cd-5f1ea9b4e11b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., ..., 1., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lief"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tVles8OxHsE",
        "outputId": "24f45672-1a63-45fa-a1c4-f4ee7b141477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lief in /usr/local/lib/python3.10/dist-packages (0.14.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lief\n",
        "import logging\n",
        "import re\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.DEBUG)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def filter_imported_functions(func_string_with_library):\n",
        "    \"\"\"\n",
        "    Filters the returned imported functions of binary to remove those with special characters (lots of noise for some reason),\n",
        "    and require functions to start with a capital letter since Windows API functions seem to obey Upper Camelcase convension.\n",
        "\n",
        "    Update: The limitation for the upper case in the preprocessing step has been removed.\n",
        "    \"\"\"\n",
        "    func_string = func_string_with_library.split(\":\")[0]\n",
        "\n",
        "    if re.match(\"^[a-zA-Z]*$\", func_string):\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def process_imported_functions_output(imports):\n",
        "    imports = list(filter(lambda x: filter_imported_functions(x), imports))\n",
        "    # imports = list(map(lambda x: remove_encoding_indicator(x), imports))\n",
        "    return imports\n",
        "\n",
        "def feature_generation(file: str, feature_vector_mapping: dict):\n",
        "    feature_vector = [0] * len(feature_vector_mapping)\n",
        "\n",
        "    try:\n",
        "        binary = lief.parse(file)\n",
        "        imports = [e.name + ':' + lib.name.lower() for lib in binary.imports for e in lib.entries]\n",
        "        imports = process_imported_functions_output(imports)\n",
        "\n",
        "        sections = [section.name for section in binary.sections]\n",
        "\n",
        "        for lib_import in imports:\n",
        "            if lib_import in feature_vector_mapping:\n",
        "                index = feature_vector_mapping[lib_import]\n",
        "                feature_vector[index] = 1\n",
        "\n",
        "        for section in sections:\n",
        "            if section in feature_vector_mapping:\n",
        "                index = feature_vector_mapping[section]\n",
        "                feature_vector[index] = 1\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error parsing {file}: {str(e)}\")\n",
        "        # You can choose to handle the error differently\n",
        "\n",
        "    return [feature_vector]"
      ],
      "metadata": {
        "id": "sMi5gRlTu3bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: load a pickle file\n",
        "\n",
        "with open('/content/drive/MyDrive/Feature_Vector/feature_vector_mapping.pk', 'rb') as f:\n",
        "    feature_vector_mapping = pickle.load(f)\n"
      ],
      "metadata": {
        "id": "zrAYum84xNfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(feature_vector_mapping)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRQwxddSxeVJ",
        "outputId": "c2e1cfc9-270f-4ec2-c862-27d574adf1d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7346"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "benign_path = \"/content/drive/MyDrive/Dataset/Benign/Benign test/ApacheMonitor.exe\"\n",
        "malware_path = \"/content/drive/MyDrive/Dataset/Virus/Virus test/Locker/VirusShare_0e4c40c9c9921673242963ccd664ab91.exe\""
      ],
      "metadata": {
        "id": "i0ER8J_oxgE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_ben = feature_generation(benign_path,feature_vector_mapping)\n",
        "X_test_mal = feature_generation(malware_path,feature_vector_mapping)\n",
        "X_test_torch_ben = torch.tensor(X_test_ben).float()\n",
        "X_test_torch_mal = torch.tensor(X_test_mal).float()\n",
        "X_test_torch_ben, X_test_torch_mal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POmFJEFHxuF5",
        "outputId": "47aba442-b244-44c6-dd8f-ae65f84aaac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 1.,  ..., 0., 0., 0.]]),\n",
              " tensor([[0., 0., 0.,  ..., 0., 0., 0.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EBD.predict(X_test_torch_ben),EBD.predict(X_test_torch_mal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_YWoCN6x3uR",
        "outputId": "3d83c589-c6e6-4762-bf74-54f423380178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 1. ... 0. 0. 0.]]\n",
            "[[0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.0981]), tensor([0.9988]))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/MalwareScore.pkl\",\"wb\") as ms:\n",
        "  pickle.dump(EBD,ms)"
      ],
      "metadata": {
        "id": "-kP_h4Hyyk8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ndGajVIHruTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EBD.save_model(\"/content/drive/MyDrive/MalwareScore.pkl\")"
      ],
      "metadata": {
        "id": "LjDrUAkYOsQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ip0ktFhFO1s2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T3bcSbczEVdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_model = pickle.load(open(\"/content/drive/MyDrive/MalwareScore.pkl\",\"rb\"))"
      ],
      "metadata": {
        "id": "LwBcKr5H3qT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = load_model.predict(X_test_torch_mal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4J6t8GwI66-",
        "outputId": "a58ae58a-03be-4e70-9736-d072b8b066f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.item()"
      ],
      "metadata": {
        "id": "PAvdH2diTg0s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa692dd4-7506-4999-95c4-a685030a7651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9988173246383667"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X-QqbtmeXXuO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}